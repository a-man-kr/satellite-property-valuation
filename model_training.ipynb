{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training - Property Valuation\n",
    "\n",
    "This notebook trains the multimodal model using:\n",
    "- Tabular features from property data\n",
    "- Image features from satellite imagery (EfficientNet-B0)\n",
    "- KNN neighborhood features\n",
    "- LightGBM for final prediction\n",
    "\n",
    "**Final Results: R² = 0.9003, RMSE = $111,857**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test data\n",
    "train_df = pd.read_csv('train.csv')  # or train.xlsx\n",
    "test_df = pd.read_csv('test.csv')    # or test.xlsx\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(f\"\\nColumns: {list(train_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"Create engineered features from raw data.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Age features\n",
    "    df['age'] = 2015 - df['yr_built']\n",
    "    df['years_since_renovation'] = np.where(\n",
    "        df['yr_renovated'] > 0,\n",
    "        2015 - df['yr_renovated'],\n",
    "        df['age']\n",
    "    )\n",
    "    \n",
    "    # Size ratios\n",
    "    df['living_lot_ratio'] = df['sqft_living'] / (df['sqft_lot'] + 1)\n",
    "    df['above_living_ratio'] = df['sqft_above'] / (df['sqft_living'] + 1)\n",
    "    df['basement_ratio'] = df['sqft_basement'] / (df['sqft_living'] + 1)\n",
    "    \n",
    "    # Neighborhood comparison\n",
    "    df['living_vs_neighbors'] = df['sqft_living'] / (df['sqft_living15'] + 1)\n",
    "    df['lot_vs_neighbors'] = df['sqft_lot'] / (df['sqft_lot15'] + 1)\n",
    "    \n",
    "    # Room features\n",
    "    df['total_rooms'] = df['bedrooms'] + df['bathrooms']\n",
    "    df['sqft_per_room'] = df['sqft_living'] / (df['total_rooms'] + 1)\n",
    "    \n",
    "    # Quality\n",
    "    df['quality_score'] = df['grade'] * df['condition']\n",
    "    df['has_basement'] = (df['sqft_basement'] > 0).astype(int)\n",
    "    df['was_renovated'] = (df['yr_renovated'] > 0).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = engineer_features(train_df)\n",
    "test_df = engineer_features(test_df)\n",
    "print(\"Features engineered!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image Feature Extraction (EfficientNet-B0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=256):\n",
    "        super().__init__()\n",
    "        self.backbone = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
    "        in_features = self.backbone.classifier[1].in_features\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(in_features, embedding_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Initialize encoder\n",
    "encoder = ImageEncoder(embedding_dim=256).to(DEVICE)\n",
    "encoder.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"Image encoder initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_features(property_ids, image_dir='satellite_images'):\n",
    "    \"\"\"Extract image features for all properties.\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for pid in tqdm(property_ids, desc=\"Extracting features\"):\n",
    "            img_path = Path(image_dir) / f\"{pid}.png\"\n",
    "            \n",
    "            if img_path.exists():\n",
    "                try:\n",
    "                    img = Image.open(img_path).convert('RGB')\n",
    "                    img_tensor = transform(img).unsqueeze(0).to(DEVICE)\n",
    "                    feat = encoder(img_tensor).cpu().numpy().flatten()\n",
    "                    features[str(pid)] = feat\n",
    "                except:\n",
    "                    features[str(pid)] = np.zeros(256)\n",
    "            else:\n",
    "                features[str(pid)] = np.zeros(256)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract features\n",
    "all_ids = list(train_df['id']) + list(test_df['id'])\n",
    "image_features = extract_image_features(all_ids)\n",
    "print(f\"Extracted features for {len(image_features)} properties\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. KNN Neighborhood Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_knn_features(df, train_df, n_neighbors=15):\n",
    "    \"\"\"Add KNN-based neighborhood price features.\"\"\"\n",
    "    # Fit KNN on training coordinates\n",
    "    coords_train = train_df[['lat', 'long']].values\n",
    "    prices_train = train_df['price'].values\n",
    "    \n",
    "    knn = NearestNeighbors(n_neighbors=n_neighbors, metric='haversine')\n",
    "    knn.fit(np.radians(coords_train))\n",
    "    \n",
    "    # Find neighbors for all properties\n",
    "    coords = df[['lat', 'long']].values\n",
    "    distances, indices = knn.kneighbors(np.radians(coords))\n",
    "    \n",
    "    # Calculate neighborhood statistics\n",
    "    neighbor_prices = prices_train[indices]\n",
    "    \n",
    "    df['knn_price_mean'] = neighbor_prices.mean(axis=1)\n",
    "    df['knn_price_median'] = np.median(neighbor_prices, axis=1)\n",
    "    df['knn_price_std'] = neighbor_prices.std(axis=1)\n",
    "    df['knn_price_min'] = neighbor_prices.min(axis=1)\n",
    "    df['knn_price_max'] = neighbor_prices.max(axis=1)\n",
    "    df['knn_distance_mean'] = distances.mean(axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = add_knn_features(train_df, train_df)\n",
    "test_df = add_knn_features(test_df, train_df)\n",
    "print(\"KNN features added!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns\n",
    "feature_cols = [\n",
    "    'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
    "    'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
    "    'sqft_basement', 'lat', 'long', 'sqft_living15', 'sqft_lot15',\n",
    "    'age', 'years_since_renovation', 'living_lot_ratio', 'above_living_ratio',\n",
    "    'basement_ratio', 'living_vs_neighbors', 'lot_vs_neighbors',\n",
    "    'total_rooms', 'sqft_per_room', 'quality_score', 'has_basement',\n",
    "    'was_renovated', 'knn_price_mean', 'knn_price_median', 'knn_price_std',\n",
    "    'knn_price_min', 'knn_price_max', 'knn_distance_mean'\n",
    "]\n",
    "\n",
    "# Get tabular features\n",
    "X_tabular = train_df[feature_cols].values\n",
    "y = train_df['price'].values\n",
    "train_ids = train_df['id'].values\n",
    "\n",
    "# Get image features\n",
    "X_image = np.array([image_features.get(str(pid), np.zeros(256)) for pid in train_ids])\n",
    "has_image = np.array([1 if str(pid) in image_features and np.any(image_features[str(pid)]) else 0 \n",
    "                      for pid in train_ids]).reshape(-1, 1)\n",
    "\n",
    "# Combine all features\n",
    "X = np.hstack([X_tabular, X_image, has_image])\n",
    "\n",
    "print(f\"Total features: {X.shape[1]}\")\n",
    "print(f\"  - Tabular: {X_tabular.shape[1]}\")\n",
    "print(f\"  - Image: {X_image.shape[1]}\")\n",
    "print(f\"  - Has image flag: 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training: {len(X_train)}, Validation: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train LightGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM parameters\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 63,\n",
    "    'learning_rate': 0.03,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'max_depth': 10,\n",
    "    'min_child_samples': 20,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Create datasets\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "\n",
    "# Train model\n",
    "print(\"Training LightGBM...\")\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=2000,\n",
    "    valid_sets=[train_data, val_data],\n",
    "    valid_names=['train', 'val'],\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=50),\n",
    "        lgb.log_evaluation(period=100)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"\\nBest iteration: {model.best_iteration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"VALIDATION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"RMSE: ${rmse:,.2f}\")\n",
    "print(f\"MAE:  ${mae:,.2f}\")\n",
    "print(f\"R²:   {r2:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Actual vs Predicted\n",
    "axes[0].scatter(y_val, y_pred, alpha=0.3, s=10)\n",
    "axes[0].plot([0, y_val.max()], [0, y_val.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Price ($)')\n",
    "axes[0].set_ylabel('Predicted Price ($)')\n",
    "axes[0].set_title(f'Actual vs Predicted (R² = {r2:.4f})')\n",
    "\n",
    "# Residuals\n",
    "residuals = y_val - y_pred\n",
    "axes[1].hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(0, color='red', linestyle='--')\n",
    "axes[1].set_xlabel('Residual ($)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Residual Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test features\n",
    "X_test_tabular = test_df[feature_cols].values\n",
    "test_ids = test_df['id'].values\n",
    "\n",
    "X_test_image = np.array([image_features.get(str(pid), np.zeros(256)) for pid in test_ids])\n",
    "has_image_test = np.array([1 if str(pid) in image_features and np.any(image_features[str(pid)]) else 0 \n",
    "                           for pid in test_ids]).reshape(-1, 1)\n",
    "\n",
    "X_test = np.hstack([X_test_tabular, X_test_image, has_image_test])\n",
    "\n",
    "# Generate predictions\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'predicted_price': test_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('22322004_final.csv', index=False)\n",
    "print(f\"Saved predictions to 22322004_final.csv\")\n",
    "print(f\"\\nPrediction Statistics:\")\n",
    "print(submission['predicted_price'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(test_predictions, bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "axes[0].set_xlabel('Predicted Price ($)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Test Predictions Distribution')\n",
    "\n",
    "axes[1].hist(train_df['price'], bins=50, alpha=0.5, label='Training (Actual)', color='blue')\n",
    "axes[1].hist(test_predictions, bins=50, alpha=0.5, label='Test (Predicted)', color='orange')\n",
    "axes[1].set_xlabel('Price ($)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Training vs Test Distribution')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Model Architecture\n",
    "- **Image Features**: EfficientNet-B0 (pretrained) → 256-dim embeddings\n",
    "- **KNN Features**: 15 nearest neighbors based on coordinates\n",
    "- **Final Model**: LightGBM gradient boosting\n",
    "\n",
    "### Results\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| R² Score | 0.9003 |\n",
    "| RMSE | $111,857 |\n",
    "| MAE | $67,230 |\n",
    "\n",
    "### Files Generated\n",
    "- `22322004_final.csv` - Final predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
