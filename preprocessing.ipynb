{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing - Property Valuation\n",
    "\n",
    "This notebook handles:\n",
    "1. Data cleaning and missing value handling\n",
    "2. Feature engineering\n",
    "3. Satellite image acquisition\n",
    "4. Image feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('..')  # Not needed when running from root\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from src.preprocessing import PropertyDataPreprocessor, get_geospatial_features\n",
    "from src.data_fetcher import SatelliteImageFetcher, create_placeholder_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/raw/train.csv')\n",
    "test_df = pd.read_csv('data/raw/test.csv')\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(f\"\\nTraining columns: {list(train_df.columns)}\")\n",
    "print(f\"\\nTest columns: {list(test_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in training data:\")\n",
    "missing_train = train_df.isnull().sum()\n",
    "print(missing_train[missing_train > 0])\n",
    "\n",
    "print(\"\\nMissing values in test data:\")\n",
    "missing_test = test_df.isnull().sum()\n",
    "print(missing_test[missing_test > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers\n",
    "print(\"Potential outliers in training data:\")\n",
    "print(f\"  Max bedrooms: {train_df['bedrooms'].max()}\")\n",
    "print(f\"  Max bathrooms: {train_df['bathrooms'].max()}\")\n",
    "print(f\"  Max sqft_living: {train_df['sqft_living'].max():,}\")\n",
    "print(f\"  Max price: ${train_df['price'].max():,}\")\n",
    "print(f\"  Min price: ${train_df['price'].min():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor and clean data\n",
    "preprocessor = PropertyDataPreprocessor()\n",
    "train_clean = preprocessor.clean_data(train_df)\n",
    "test_clean = preprocessor.clean_data(test_df)\n",
    "\n",
    "print(\"Data cleaned successfully!\")\n",
    "print(f\"New columns after date processing: {[c for c in train_clean.columns if c not in train_df.columns]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineer features\n",
    "train_features = preprocessor.engineer_features(train_clean)\n",
    "test_features = preprocessor.engineer_features(test_clean)\n",
    "\n",
    "# Show new features\n",
    "new_features = [c for c in train_features.columns if c not in train_clean.columns]\n",
    "print(f\"Engineered features ({len(new_features)}):\")\n",
    "for f in new_features:\n",
    "    print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize engineered features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Age vs Price\n",
    "axes[0, 0].scatter(train_features['age'], train_features['price'], alpha=0.3, s=5)\n",
    "axes[0, 0].set_xlabel('Property Age (years)')\n",
    "axes[0, 0].set_ylabel('Price ($)')\n",
    "axes[0, 0].set_title('Age vs Price')\n",
    "\n",
    "# Living/Lot Ratio vs Price\n",
    "axes[0, 1].scatter(train_features['living_lot_ratio'], train_features['price'], alpha=0.3, s=5)\n",
    "axes[0, 1].set_xlabel('Living/Lot Ratio')\n",
    "axes[0, 1].set_ylabel('Price ($)')\n",
    "axes[0, 1].set_title('Living/Lot Ratio vs Price')\n",
    "axes[0, 1].set_xlim(0, 1)\n",
    "\n",
    "# Living vs Neighbors\n",
    "axes[0, 2].scatter(train_features['living_vs_neighbors'], train_features['price'], alpha=0.3, s=5)\n",
    "axes[0, 2].set_xlabel('Living Size / Neighbor Avg')\n",
    "axes[0, 2].set_ylabel('Price ($)')\n",
    "axes[0, 2].set_title('Relative Living Size vs Price')\n",
    "axes[0, 2].set_xlim(0, 3)\n",
    "\n",
    "# Quality Score vs Price\n",
    "axes[1, 0].scatter(train_features['quality_score'], train_features['price'], alpha=0.3, s=5)\n",
    "axes[1, 0].set_xlabel('Quality Score (Grade × Condition)')\n",
    "axes[1, 0].set_ylabel('Price ($)')\n",
    "axes[1, 0].set_title('Quality Score vs Price')\n",
    "\n",
    "# Sqft per Room vs Price\n",
    "axes[1, 1].scatter(train_features['sqft_per_room'], train_features['price'], alpha=0.3, s=5)\n",
    "axes[1, 1].set_xlabel('Sqft per Room')\n",
    "axes[1, 1].set_ylabel('Price ($)')\n",
    "axes[1, 1].set_title('Space per Room vs Price')\n",
    "axes[1, 1].set_xlim(0, 1000)\n",
    "\n",
    "# Renovation Impact\n",
    "train_features.boxplot(column='price', by='was_renovated', ax=axes[1, 2])\n",
    "axes[1, 2].set_xlabel('Was Renovated (0=No, 1=Yes)')\n",
    "axes[1, 2].set_ylabel('Price ($)')\n",
    "axes[1, 2].set_title('Renovation Impact on Price')\n",
    "\n",
    "plt.suptitle('')\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/figures/engineered_features.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Geospatial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add geospatial features\n",
    "train_geo = get_geospatial_features(train_features)\n",
    "\n",
    "# Visualize distance features\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "scatter1 = axes[0].scatter(train_geo['long'], train_geo['lat'], \n",
    "                           c=train_geo['dist_to_downtown'], cmap='viridis', \n",
    "                           alpha=0.5, s=5)\n",
    "plt.colorbar(scatter1, ax=axes[0], label='Distance to Downtown')\n",
    "axes[0].set_xlabel('Longitude')\n",
    "axes[0].set_ylabel('Latitude')\n",
    "axes[0].set_title('Distance to Seattle Downtown')\n",
    "\n",
    "axes[1].scatter(train_geo['dist_to_downtown'], train_geo['price'], alpha=0.3, s=5)\n",
    "axes[1].set_xlabel('Distance to Downtown')\n",
    "axes[1].set_ylabel('Price ($)')\n",
    "axes[1].set_title('Distance to Downtown vs Price')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/figures/geospatial_features.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Satellite Image Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if images already exist\n",
    "image_dir = Path('data/images')\n",
    "existing_images = list(image_dir.glob('*.png'))\n",
    "print(f\"Existing images: {len(existing_images)}\")\n",
    "\n",
    "# Combine train and test for image fetching\n",
    "all_df = pd.concat([train_df, test_df])\n",
    "print(f\"Total properties: {len(all_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Create placeholder images (for testing without API)\n",
    "# Uncomment to use:\n",
    "# create_placeholder_images(all_df, 'data/images')\n",
    "\n",
    "# Option 2: Fetch real satellite images (requires API key)\n",
    "# Set your API key in environment:\n",
    "# export MAPBOX_ACCESS_TOKEN=\"your_token_here\"\n",
    "\n",
    "# fetcher = SatelliteImageFetcher(api_provider='mapbox', output_dir='data/images')\n",
    "# fetcher.fetch_all_images(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images if available\n",
    "from PIL import Image\n",
    "\n",
    "sample_ids = train_df.sample(min(4, len(train_df)))['id'].values\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, pid in enumerate(sample_ids):\n",
    "    img_path = image_dir / f\"{pid}.png\"\n",
    "    if img_path.exists():\n",
    "        img = Image.open(img_path)\n",
    "        axes[idx].imshow(img)\n",
    "        price = train_df[train_df['id'] == pid]['price'].values[0]\n",
    "        axes[idx].set_title(f'ID: {pid}\\nPrice: ${price:,.0f}')\n",
    "    else:\n",
    "        axes[idx].text(0.5, 0.5, 'Image not found', ha='center', va='center')\n",
    "        axes[idx].set_title(f'ID: {pid}')\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/figures/sample_satellite_images.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Image Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.models.cnn_encoder import SatelliteImageEncoder, ImageFeatureExtractor\n",
    "\n",
    "# Initialize encoder\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "encoder = SatelliteImageEncoder(embedding_dim=256, pretrained=True)\n",
    "extractor = ImageFeatureExtractor(encoder, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for all properties\n",
    "all_ids = all_df['id'].tolist()\n",
    "\n",
    "features_path = Path('data/processed/image_features.npz')\n",
    "if features_path.exists():\n",
    "    print(\"Loading cached features...\")\n",
    "    image_features = extractor.load_features(str(features_path))\n",
    "else:\n",
    "    print(\"Extracting features...\")\n",
    "    image_features = extractor.extract_batch(all_ids, str(image_dir))\n",
    "    extractor.save_features(image_features, str(features_path))\n",
    "\n",
    "print(f\"Extracted features for {len(image_features)} properties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distribution\n",
    "if image_features:\n",
    "    sample_features = np.array([image_features[str(pid)] for pid in list(image_features.keys())[:100]])\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Feature distribution\n",
    "    axes[0].hist(sample_features.flatten(), bins=50, alpha=0.7)\n",
    "    axes[0].set_xlabel('Feature Value')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].set_title('Image Feature Distribution')\n",
    "    \n",
    "    # Feature correlation heatmap (subset)\n",
    "    corr = np.corrcoef(sample_features[:, :20].T)\n",
    "    im = axes[1].imshow(corr, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "    plt.colorbar(im, ax=axes[1])\n",
    "    axes[1].set_title('Feature Correlation (first 20 dims)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('outputs/figures/image_features.png', dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prepare Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use preprocessor to prepare final training data\n",
    "preprocessor = PropertyDataPreprocessor()\n",
    "preprocessor.load_data(\n",
    "    train_path='data/raw/train.csv',\n",
    "    test_path='data/raw/test.csv'\n",
    ")\n",
    "\n",
    "data = preprocessor.prepare_for_training(val_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(data['X_train'])}\")\n",
    "print(f\"Validation samples: {len(data['X_val'])}\")\n",
    "print(f\"Number of features: {len(data['feature_columns'])}\")\n",
    "print(f\"\\nFeature columns:\")\n",
    "for i, col in enumerate(data['feature_columns']):\n",
    "    print(f\"  {i+1}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessor for later use\n",
    "preprocessor.save_preprocessor('data/processed/preprocessor.pkl')\n",
    "print(\"Preprocessor saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Data Cleaning\n",
    "- Handled missing values with median imputation\n",
    "- Converted date to year/month features\n",
    "\n",
    "### Feature Engineering (30+ features)\n",
    "- **Age features**: property age, years since renovation\n",
    "- **Size ratios**: living/lot, above/living, basement ratio\n",
    "- **Neighborhood comparison**: living vs neighbors, lot vs neighbors\n",
    "- **Room features**: total rooms, sqft per room\n",
    "- **Quality**: grade × condition score\n",
    "- **Binary**: has basement, was renovated\n",
    "\n",
    "### Image Features\n",
    "- 256-dimensional embeddings from EfficientNet-B0 (pretrained on ImageNet)\n",
    "- Captures visual context from satellite imagery\n",
    "\n",
    "### Next Steps\n",
    "- Proceed to model training notebook (03_model_training.ipynb)\n",
    "- Or run `python run_improved_pipeline.py` for the best model (R² = 0.9003)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
